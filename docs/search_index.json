[["index.html", "Whole Exome Sequencing Platform 1 Overview", " Whole Exome Sequencing Platform Marc Henein and Zachary Sentell 2023-08-18 1 Overview We run the pipeline on the Compute Canada servers. Pre-processing steps will be executed with the Sarek pipeline from nf-core (Ewels et al. 2020). Raw sequence pre-processing and alignment. Germline variant calling for SNVs and indels. Variant annotation and trio analysis to identify disease-causing variants. "],["align.html", "2 Alignment 2.1 Pre-processing 2.2 Mark Duplicates 2.3 Base Quality Score Recalibration 2.4 Quality Control", " 2 Alignment Based on GATK best practices. 2.1 Pre-processing Data processing will start with either FASTQ files directly from the sequencer, or pre-processed BAM files of raw sequence data that has been aligned to the reference genome. Quality control of raw reads with FastQC, a quality control tool for high throughput sequence data, written by Simon Andrews at the Babraham Institute in Cambridge. module load fastqc Trimming raw reads with fastp, an ultra-fast all-in-one FASTQ preprocessor. Mapping reads to GRCh38 reference genome with BWA-MEM algorithm. Convert SAM to BAM with samtools. module load fastp module load bwa mem module load samtools export reference=$MUGQIC_INSTALL_HOME/genomes/species/Homo_sapiens.GRCh38/genome/bwa_index/Homo_sapiens.GRCh38.fa fastp -i EC25_1.fq.gz -I EC25_2.fq.gz \\ --stdout --thread 2 \\ -j &quot;fastp-EC25.json&quot; \\ -h &quot;fastp-EC25.html&quot; \\ 2&gt; &quot;fastp-EC25.log&quot; \\ | bwa mem -v 2 -M -t 32 -p \\ $reference - 2&gt; &quot;bwa-EC25.log&quot; \\ | samtools view -@ 16 \\ -O BAM \\ -o &quot;aligned_EC25.bam&quot; \\ 2&gt; &quot;samtools-EC25.log&quot; 2.2 Mark Duplicates Identify read pairs that are likely to have originated from duplicates of the same DNA fragment with GATK MarkDuplicates. java -Xms60G -Xmx60G -jar $GATK_JAR MarkDuplicatesSpark \\ -I aligned_EC25.bam \\ -O aligned_EC25_markdup.bam \\ --spark-master local[12] 2.3 Base Quality Score Recalibration GATK BaseRecalibrator generates a recalibration table based on various covariates, i.e., read group, reported quality score, machine cycle, and nucleotide context. GATK ApplyBQSR recalibrates the base qualities of the input reads based on the recalibration table. java -Xms4G -Xmx4G -jar $GATK_JAR BaseRecalibrator \\ -I aligned_EC25_markdup.bam \\ -R $reference \\ -O aligned_EC25_markdup_bqsr.report \\ --known-sites BQSR/Homo_sapiens_assembly38.dbsnp138.vcf \\ --known-sites BQSR/Homo_sapiens_assembly38.known_indels.vcf.gz \\ --known-sites BQSR/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz java -Xms2G -Xmx2G -jar $GATK_JAR ApplyBQSR \\ -I aligned_EC25_markdup.bam \\ -R $reference \\ --bqsr-recal-file aligned_EC25_markdup_bqsr.report \\ -O aligned_EC25_markdup_bqsr.bam 2.4 Quality Control samtools stats collects statistics from CRAM files and outputs in a text format. Mosdepth reports information for the evaluation of the quality of the provided alignment data. In short, the basic statistics of the alignment (number of reads, coverage, GC-content, etc.) are summarized and a number of useful graphs are produced. MultiQC is a visualization tool that generates a single HTML report summarizing all samples in your project. "],["calling.html", "3 Variant Calling 3.1 SNV/Indel Calling 3.2 Variant Filtration 3.3 Genotype Posteriors", " 3 Variant Calling 3.1 SNV/Indel Calling First, call variants with GATK4 HaplotypeCaller. exome=sureselectV4_padded_hg38.bed names=&#39;father mother proband&#39; for name in $names do input=&quot;BAM/${name}.recal.bam&quot; output=&quot;${name}_raw_variants.g.vcf.gz&quot; java -Xmx6g -jar $GATK_JAR HaplotypeCaller \\ -R $reference \\ -I $input \\ -O $output \\ -L $exome \\ -ip 0 \\ -ERC GVCF done Then, combine gVCFs and compile genotypes at sites with a variant in at least one sample. # Combine gVCFs find . -maxdepth 1 -type f -name &quot;*_raw_variants.g.vcf.gz&quot; &gt; input.list java -Xmx6g -jar $GATK_JAR CombineGVCFs \\ -R $reference \\ -V input.list \\ -O joint/joint_raw_variants.g.vcf.gz # Genotype gVCF java -Xmx6g -jar $GATK_JAR GenotypeGVCFs \\ -R $reference \\ -V joint/joint_raw_variants.g.vcf.gz \\ -O joint/joint_raw_variants_genotype.vcf.gz 3.2 Variant Filtration For SNVs, use VQSR to filter variants. VQSR creates a training set of high-confidence variants and learns which region of the parameter space is associated with high quality calls. # Sties only java -Xmx2g -jar $GATK_JAR MakeSitesOnlyVcf \\ -I joint/joint_raw_variants_genotype.vcf.gz \\ -O joint/joint_raw_variants_genotype_sitesonly.vcf.gz # VQSR for SNPs java -Xmx6g -jar $GATK_JAR VariantRecalibrator \\ -R $reference \\ -V joint/joint_raw_variants_genotype_sitesonly.vcf.gz \\ --trust-all-polymorphic \\ -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.8 -tranche 99.6 -tranche 99.5 -tranche 99.4 -tranche 99.3 -tranche 99.0 -tranche 98.0 -tranche 97.0 -tranche 90.0 \\ -an QD -an MQRankSum -an ReadPosRankSum -an FS -an MQ -an SOR -an DP \\ -resource:hapmap,known=false,training=true,truth=true,prior=15 VQSR/hg38/hapmap_3.3.hg38.vcf.gz \\ -resource:omni,known=false,training=true,truth=true,prior=12 VQSR/hg38/1000G_omni2.5.hg38.vcf.gz \\ -resource:1000G,known=false,training=true,truth=false,prior=10 VQSR/hg38/1000G_phase1.snps.high_confidence.hg38.vcf.gz \\ -resource:dbsnp,known=true,training=false,truth=false,prior=7 VQSR/hg38/Homo_sapiens_assembly38.dbsnp138.vcf \\ --max-gaussians 4 \\ -mode SNP \\ -O joint/cohort_snps.recal \\ --tranches-file joint/cohort_snps.tranches \\ --rscript-file joint/output_snp.plots.R java -Xmx6g -jar $GATK_JAR ApplyVQSR \\ -R $reference \\ -V joint/joint_raw_variants_genotype.vcf.gz \\ -O joint/snp.recalibrated.vcf.gz \\ --recal-file joint/cohort_snps.recal \\ --tranches-file joint/cohort_snps.tranches \\ --truth-sensitivity-filter-level 99.7 \\ --create-output-variant-index true \\ -mode SNP Manually filter indels by setting hard thresholds. # Select indels java -Xmx2g -jar $GATK_JAR SelectVariants \\ -R $reference \\ -V joint/joint_raw_variants_genotype.vcf.gz \\ --select-type-to-include INDEL \\ -O joint/raw_indels.vcf.gz # Indels hard threshold java -Xmx2g -jar $GATK_JAR VariantFiltration \\ -R $reference \\ -V joint/raw_indels.vcf.gz \\ -O joint/filtered_indels.vcf.gz \\ -filter &quot;QD &lt; 2.0&quot; --filter-name &quot;QD2&quot; \\ -filter &quot;QUAL &lt; 30.0&quot; --filter-name &quot;QUAL30&quot; \\ -filter &quot;FS &gt; 200.0&quot; --filter-name &quot;FS200&quot; \\ -filter &quot;ReadPosRankSum &lt; -20.0&quot; --filter-name &quot;ReadPosRankSum-20&quot; Merge SNPs and indels into a single VCF. java -Xmx2g -jar $GATK_JAR SelectVariants \\ -R $reference \\ -V joint/snp.recalibrated.vcf.gz \\ --select-type-to-include SNP \\ -O joint/snp.recalibrated_minus_indel.vcf.gz java -Xmx2g -jar $GATK_JAR MergeVcfs \\ -I joint/snp.recalibrated_minus_indel.vcf.gz \\ -I joint/filtered_indels.vcf.gz \\ -O joint/output_vqsr_snps_hard_indels.vcf.gz 3.3 Genotype Posteriors java -Xmx2g -jar $GATK_JAR CalculateGenotypePosteriors \\ -V joint/output_vqsr_snps_hard_indels.vcf.gz \\ -ped pedigree.ped \\ --supporting-callsets af-only-gnomad.hg38.vcf.gz \\ -O trio_refined.vcf.gz "],["statistical-genetics.html", "4 Statistical Genetics 4.1 Phasing 4.2 Kinship 4.3 Runs of Homozygosity 4.4 Linkage Analysis 4.5 Population Substructure", " 4 Statistical Genetics 4.1 Phasing WhatsHap phases genotypes in a pedigree using the Mendelian transmission rules and physical phasing based on reads that span two or more heterozygous variants. whatshap phase --ped pedigree.ped \\ -o phased_whatshap.vcf joint/output_vqsr_variants.vcf.gz \\ aligned_HG002.bam aligned_HG003.bam aligned_HG004.bam \\ --tag=PS --no-reference --indels 4.2 Kinship We seek to confirm pedigrees and identify hidden relatedness between samples. We first select SNPs in approximate linkage equilibrium with Linkdatagen based on the genetic linkage map of HapMap SNPs. Linkdatagen also eliminates Mendelian inconsitencies in the data. perl vcf2linkdatagen.pl \\ -variantCaller mpileup \\ -annotfile annotHapMap2U.txt \\ -pop CEU -mindepth 10 -missingness 0 \\ -idlist MyVCFlist.txt &gt; MySNPs.brlmm perl linkdatagen.pl \\ -data m -pedfile MyPed.ped \\ -whichSamplesFile MyWS.ws \\ -callFile MySNPs.brlmm \\ -annotFile annotHapMap2U.txt \\ -pop CEU -binsize 0.3 \\ -MendelErrors removeSNPs -prog pl \\ -outputDir MyPed_HapMap2_pl &gt; MyPed_HapMap2_pl.out We construct an allele frequency report for the chosen SNPs. map &lt;- read_delim(file = &quot;plink.map&quot;, delim = &quot; &quot;, col_select = 1:4, col_names = c(&quot;CHR&quot;, &quot;SNP&quot;, &quot;cM&quot;, &quot;bp&quot;)) ord &lt;- read_tsv(file = &quot;orderedSNPs.txt&quot;) freq_pl &lt;- map %&gt;% left_join(ord, by = &quot;SNP&quot;) %&gt;% dplyr::select(CHR, SNP, `Allele freq`) %&gt;% mutate(A1=&quot;1&quot;) %&gt;% mutate(A1=&quot;1&quot;) %&gt;% mutate(A2=&quot;2&quot;) %&gt;% mutate(NCHROBS=&quot;300&quot;) %&gt;% dplyr::select(CHR, SNP, A1, A2, `Allele freq`, NCHROBS) %&gt;% rename(`Allele freq` = &quot;MAF&quot;) write_delim(freq_pl, &quot;freq_pl.frq&quot;, delim = &quot; &quot;) Alternatively, with a sufficient number of samples, we can estimate the linkage disequilibrium between alleles and remove correlated SNPs. plink --file data --indep 50 5 2 We then calculate the empirical kinship coefficient by estimating identity by descent using identity by state and allele frequencies. We run this calculation in PLINK. plink --file plink --genome --read-freq freq_pl.frq We also run this calculation using MendelKinship from the OpenMendel project. using MendelKinship, CSV Kinship(&quot;control_compare.txt&quot;) 4.3 Runs of Homozygosity HomozygosityMapper https://www.homozygositymapper.org/, PLINK 4.4 Linkage Analysis Linkdatagen, PBAP, MORGAN, MERLIN, Allegro, OpenMendel, Pedminer perl linkdatagen.pl \\ -data m -pedfile MyPed.ped \\ -whichSamplesFile MyWS.ws \\ -callFile MySNPs.brlmm \\ -annotFile annotHapMap2U.txt \\ -pop CEU -binsize 0.3 \\ -MendelErrors removeSNPs -prog me \\ -outputDir MyPed_HapMap2 &gt; MyPed_HapMap2_me.out Two-point linkage Multipoint linkage 4.5 Population Substructure Given a large population sample, we cluster individuals by degree of identity by state using PLINK in order to identify subgroups with shared ancestry. plink --file mydata --cluster # dimensional reduction to 4D then plot two coordinates plink --file mydata --read-genome plink.genome --cluster --mds-plot 4 "],["variant-annotation.html", "5 Variant Annotation 5.1 Filtration 5.2 De Novo Variants 5.3 Homozygous Variants 5.4 Compound Heterozygous Variants 5.5 X Chromosome 5.6 Disease Genes", " 5 Variant Annotation Annotate the variants with VEP for molecular consequence, allele frequency and a set of pathogenicity prediction tools. apptainer exec -B vep_data:/opt/vep/.vep vep.sif /opt/vep/src/ensembl-vep/vep \\ --dir_cache /opt/vep/.vep/ \\ --dir_plugins /opt/vep/.vep/Plugins/ \\ -i /opt/vep/.vep/output_vqsr_snps_hard_indels.vcf.gz \\ -o /opt/vep/.vep/ensembl_annotated.txt \\ --individual EC27_proband \\ --everything \\ --check_existing \\ --xref_refseq \\ --fasta /opt/vep/.vep/Homo_sapiens.GRCh38.fa \\ --hgvs \\ --hgvsg \\ --plugin CADD,/opt/vep/.vep/Plugins/data/grch38/whole_genome_SNVs_grch38.tsv.gz,/opt/vep/.vep/Plugins/data/grch38/gnomad.genomes.r3.0.indel_grch38.tsv.gz \\ --plugin PrimateAI,/opt/vep/.vep/Plugins/data/grch38/PrimateAI_scores_v0.2_GRCh38_sorted.tsv.bgz \\ --plugin SpliceAI,snv=/opt/vep/.vep/Plugins/data/grch38/spliceai_scores.raw.snv.hg38.vcf.gz,indel=/opt/vep/.vep/Plugins/data/grch38/spliceai_scores.raw.indel.hg38.vcf.gz \\ --plugin EVE,file=/opt/vep/.vep/Plugins/data/grch38/eve_merged.vcf.gz \\ --plugin Mastermind,/opt/vep/.vep/Plugins/data/grch38/mastermind_cited_variants_reference-2023.04.02-grch38.vcf.gz \\ --plugin dbNSFP,/opt/vep/.vep/Plugins/data/grch38/dbNSFP4.3a_grch38.gz,MutationTaster_score,MutationTaster_pred \\ --plugin REVEL,/opt/vep/.vep/Plugins/data/grch38/new_tabbed_revel_grch38.tsv.gz \\ --custom /opt/vep/.vep/Plugins/data/grch38/clinvar.vcf.gz,ClinVar,vcf,exact,0,CLNSIG,CLNREVSTAT,CLNDN \\ --cache \\ --merged \\ --offline \\ --use_given_ref \\ --force_overwrite \\ --assembly GRCh38 \\ --fork 2 \\ --buffer_size 1000 \\ --tab 5.1 Filtration Perform a first round of filtering with VEP to reduce the size of the VCF to be loaded into R. In particular, select variants with high or moderate impact and an allele frequency smaller than 0.05. apptainer exec -B vep_data:/opt/vep/.vep vep.sif /opt/vep/src/ensembl-vep/filter_vep \\ -i /opt/vep/.vep/ensembl_annotated.txt \\ -out /opt/vep/.vep/ensembl_ann_vep_filt.txt \\ --filter &quot;(IMPACT is HIGH or IMPACT is MODERATE) and (gnomADe_AF &lt;= 0.05 or not gnomADe_AF)&quot; \\ --force_overwrite \\ --format tab Load the WhatsHap phased variants into R and select autosomal variants. library(tidyverse) library(VariantAnnotation) mother = &quot;EC25&quot; father = &quot;EC26&quot; proband = &quot;EC27&quot; wh &lt;- readVcf(&quot;phased_whatshap_refined.vcf&quot;, &quot;hg38&quot;) wh &lt;- expand(wh) pos &lt;- rowRanges(wh) pos2 &lt;- as.data.frame(pos) %&gt;% as_tibble # Genotype wh_geno &lt;- geno(wh)$GT %&gt;% as_tibble() %&gt;% dplyr::rename(&quot;mother&quot;= sym(mother), &quot;father&quot;= sym(father), &quot;proband&quot;= sym(proband)) # Phasing block wh_ps &lt;- geno(wh)$PS %&gt;% as_tibble() %&gt;% dplyr::rename(&quot;PS_mother&quot; = sym(mother), &quot;PS_father&quot;= sym(father), &quot;PS_proband&quot;= sym(proband)) # Genotype quality wh_gq &lt;- geno(wh)$GQ %&gt;% as_tibble() %&gt;% dplyr::rename(&quot;GQ_mother&quot; = sym(mother), &quot;GQ_father&quot;= sym(father), &quot;GQ_proband&quot;= sym(proband)) # Join genotype, phasing block and genotype quality wh_geno0 &lt;- bind_cols(pos2,wh_geno,wh_gq,wh_ps) # Identify alternate alleles with number wh_geno01 &lt;- wh_geno0 %&gt;% group_by(seqnames,start,end,width,REF) %&gt;% mutate(counter = row_number()) %&gt;% ungroup() # Convert variant formatting to VEP format. Add 1 to indel start site. wh_geno01 &lt;- wh_geno01 %&gt;% mutate(Location = ifelse( width==1, ifelse( nchar(ALT)==1, paste(seqnames,start,sep=&quot;:&quot;), paste0(seqnames,&quot;:&quot;,start,&quot;-&quot;,start+1)), ifelse( start+1==end, paste0(seqnames,&quot;:&quot;,start+1), paste0(seqnames,&quot;:&quot;,start+1,&quot;-&quot;,end)))) %&gt;% mutate(Allele = ifelse(substr(REF,1,1)==substr(ALT,1,1), substr(ALT,2,nchar(ALT)), ALT)) wh_geno01$Allele[wh_geno01$Allele==&quot;&quot;] &lt;- &quot;-&quot; # Overlapping deletions wh_geno_overlap &lt;- wh_geno01 %&gt;% dplyr::filter(ALT==&quot;&quot;) wh_geno1 &lt;- wh_geno01 %&gt;% dplyr::filter(ALT!=&quot;&quot;) wh_geno1 &lt;- wh_geno1[c(21,22,11:19,20)] # Select X chromosome wh_geno_X &lt;- wh_geno1 %&gt;% dplyr::filter(str_detect(Location,&quot;chrX&quot;)) # Select autosomal variants wh_geno_auto &lt;- wh_geno1 %&gt;% dplyr::filter(!str_detect(Location,&quot;chrX&quot;)) %&gt;% dplyr::filter(!str_detect(Location,&quot;chrY&quot;)) %&gt;% dplyr::filter(!str_detect(Location,&quot;M&quot;)) wh_geno_auto Manually remove the hashtag before the line of column titles in ensembl_ann_vep_filt.txt. Load the filtered variants into R. Select variants with an allele frequency &lt;0.01 that fall in RefSeq transcripts. result &lt;- read_table(&quot;ensembl_ann_vep_filt_refined_08_07_23.txt&quot;, comment = &quot;#&quot;, na=&quot;-&quot;, col_types = list( Uploaded_variation= col_factor(), Gene=col_factor(), Feature=col_factor(), MANE_PLUS_CLINICAL = col_character(), MOTIF_NAME = col_character(), HIGH_INF_POS = col_character(), TRANSCRIPTION_FACTORS = col_character(), PUBMED=col_character(), MOTIF_POS = col_character())) result$Allele[is.na(result$Allele)] &lt;- &quot;-&quot; result1 &lt;- result %&gt;% as_tibble %&gt;% left_join(wh_geno1, by = c(&quot;Location&quot;,&quot;Allele&quot;)) refseq0 &lt;- result1 %&gt;% dplyr::filter(SOURCE == &quot;RefSeq&quot;) %&gt;% dplyr::filter(gnomADe_AF&lt;=0.01|is.na(gnomADe_AF)) %&gt;% dplyr::filter(!(is.na(gnomADe_AF) &amp; gnomADg_AF &gt; 0.01)) %&gt;% dplyr::filter(!(str_detect(Feature,&quot;XM&quot;))) %&gt;% select_if(~any(!is.na(.))) Add gene-level information. library(ontologyIndex) # OMIM omim &lt;- read_tsv(&quot;~/Documents/kidney_panel/omim/genemap2_edit.txt&quot;, name_repair=&quot;universal&quot;, col_types=list(Entrez.Gene.ID = col_factor())) %&gt;% dplyr::rename(OMIM_Phenotypes = Phenotypes) %&gt;% dplyr::select(Entrez.Gene.ID,OMIM_Phenotypes) # Human Phenotype Ontology hpo_data &lt;- read_tsv(&quot;~/Documents/kidney_panel/genes_to_phenotype.txt&quot;, col_types=list(entrez_gene_id = col_factor())) hpo &lt;- get_ontology(file = &#39;~/Documents/kidney_panel/hp_obo.txt&#39;, propagate_relationships = &quot;is_a&quot;, extract_tags = &quot;minimal&quot;) hpo_kidney &lt;- get_descendants(hpo, roots=&quot;HP:0000077&quot;) #Abnormality of the kidney gen_hpo_kidney &lt;- hpo_data %&gt;% dplyr::filter(hpo_term_id %in% hpo_kidney) %&gt;% dplyr::arrange(frequency_hpo) %&gt;% dplyr::mutate(frequency = case_when( frequency_hpo == &quot;HP:0040284&quot; ~ &quot; (very rare)&quot;, frequency_hpo == &quot;HP:0040283&quot; ~ &quot; (occasional)&quot;, frequency_hpo == &quot;HP:0040282&quot; ~ &quot; (frequent)&quot;, frequency_hpo == &quot;HP:0040281&quot; ~ &quot; (very frequent)&quot;, frequency_hpo == &quot;HP:0040280&quot; ~ &quot; (obligate)&quot;, TRUE ~ &quot;&quot;)) %&gt;% unite(&quot;renal_hpo_term&quot;, c(hpo_term_name, frequency), remove = FALSE, sep = &quot;&quot;) %&gt;% dplyr::group_by(entrez_gene_id) %&gt;% dplyr::summarise(renal_hpo_term = toString(unique(renal_hpo_term))) gen_hpo_extra &lt;- hpo_data %&gt;% dplyr::filter(frequency_hpo %in% c(&quot;HP:0040281&quot;, &quot;HP:0040280&quot;)) %&gt;% dplyr::arrange(frequency_hpo) %&gt;% dplyr::filter(!(hpo_term_id %in% hpo_kidney)) %&gt;% dplyr::group_by(entrez_gene_id) %&gt;% dplyr::summarise(extrarenal_hpo_term = toString(unique(hpo_term_name))) # ClinGen clingen &lt;- read_csv(&quot;~/Documents/kidney_panel/Clingen-Curation.csv&quot;, skip = 3) %&gt;% dplyr::mutate(assertion=gsub(&quot;\\\\s*\\\\([^\\\\)]+\\\\)&quot;,&quot;&quot;, gene_disease_validity_assertion_classifications)) %&gt;% dplyr::mutate(assertion=paste(&quot;(&quot;,assertion,&quot;)&quot;,sep=&quot;&quot;)) %&gt;% dplyr::mutate(assertion=if_else(assertion==&quot;(NA)&quot;,NA,assertion)) %&gt;% unite(&quot;disease&quot;, c(disease_label, assertion), remove = FALSE, na.rm=TRUE, sep = &quot; &quot;) %&gt;% dplyr::group_by(hgnc_id) %&gt;% dplyr::summarise(clingen_disease_label = paste(disease,collapse=&quot;; &quot;)) # GenCC including Orphanet data gencc &lt;- read_tsv(&quot;~/Documents/kidney_panel/gencc-submissions.tsv&quot;) gencc_def &lt;- gencc %&gt;% dplyr::filter(submitter_title != &quot;Orphanet&quot;) %&gt;% dplyr::filter(classification_title == &quot;Definitive&quot;) %&gt;% dplyr::group_by(gene_symbol, gene_curie, disease_title) %&gt;% dplyr::summarise( submitter_title = toString(unique(submitter_title)), moi_title = toString(unique(moi_title)), disease_curie = toString(unique(disease_curie)), disease_original_curie = toString(unique(disease_original_curie)), classification_title = toString(classification_title), submitted_as_pmids = toString(unique(submitted_as_pmids))) %&gt;% dplyr::mutate(submitter = paste(&quot;(&quot;, submitter_title, &quot;)&quot;, sep = &quot;&quot;)) %&gt;% tidyr::unite(&quot;gencc_disease_definitive&quot;, c(disease_title, submitter), remove = FALSE, sep = &quot; &quot;) %&gt;% dplyr::select(gene_curie, gencc_disease_definitive) %&gt;% dplyr::group_by(gene_curie) %&gt;% dplyr::summarise(gencc_disease_definitive = paste(unique(gencc_disease_definitive), collapse=&quot;; &quot;)) gencc_strong &lt;- gencc %&gt;% dplyr::filter(submitter_title != &quot;Orphanet&quot;) %&gt;% dplyr::filter(classification_title == &quot;Strong&quot;) %&gt;% dplyr::group_by(gene_symbol, gene_curie, disease_title) %&gt;% dplyr::summarise( submitter_title = toString(unique(submitter_title)), moi_title = toString(unique(moi_title)), disease_curie = toString(unique(disease_curie)), disease_original_curie = toString(unique(disease_original_curie)), classification_title = toString(classification_title), submitted_as_pmids = toString(unique(submitted_as_pmids))) %&gt;% dplyr::mutate(submitter = paste(&quot;(&quot;, submitter_title, &quot;)&quot;, sep = &quot;&quot;)) %&gt;% tidyr::unite(&quot;gencc_disease_strong&quot;, c(disease_title, submitter), remove = FALSE, sep = &quot; &quot;) %&gt;% dplyr::select(gene_curie, gencc_disease_strong) %&gt;% dplyr::group_by(gene_curie) %&gt;% dplyr::summarise(gencc_disease_strong = paste(unique(gencc_disease_strong), collapse=&quot;; &quot;)) orphanet &lt;- gencc %&gt;% dplyr::filter(submitter_title == &quot;Orphanet&quot;) %&gt;% dplyr::group_by(gene_curie) %&gt;% dplyr::summarise(orphanet_disease = toString(disease_title), orphanet_moi = toString(unique(moi_title))) # Join refseq01 &lt;- refseq0 %&gt;% left_join(omim, by=join_by(Gene==Entrez.Gene.ID)) %&gt;% left_join(gen_hpo_kidney, by=join_by(Gene==entrez_gene_id)) %&gt;% left_join(gen_hpo_extra, by=join_by(Gene==entrez_gene_id)) %&gt;% left_join(clingen, by=join_by(HGNC_ID==hgnc_id)) %&gt;% left_join(gencc_def, by=join_by(HGNC_ID==gene_curie)) %&gt;% left_join(gencc_strong, by=join_by(HGNC_ID==gene_curie)) %&gt;% left_join(orphanet, by=join_by(HGNC_ID==gene_curie)) refseq_X &lt;- refseq01 %&gt;% dplyr::filter(str_detect(Uploaded_variation,&quot;X&quot;)) refseq &lt;- refseq01 %&gt;% dplyr::filter(!str_detect(Uploaded_variation,&quot;X&quot;)) %&gt;% dplyr::filter(!str_detect(Uploaded_variation,&quot;Y&quot;)) %&gt;% dplyr::filter(!str_detect(Uploaded_variation,&quot;M&quot;)) refseq 5.2 De Novo Variants Select de novo variants in the proband. geno_novo_all &lt;- wh_geno_auto %&gt;% dplyr::filter(! ( ( ( str_detect(mother, substr(proband,1,1)) | str_detect(mother, &quot;\\\\.&quot;) ) &amp; (str_detect(father, substr(proband,3,3)) | str_detect(father, &quot;\\\\.&quot;) ) ) | ( ( str_detect(father, substr(proband,1,1)) | str_detect(father, &quot;\\\\.&quot;) ) &amp; (str_detect(mother, substr(proband,3,3)) | str_detect(mother, &quot;\\\\.&quot;) ) ) ) ) %&gt;% dplyr::filter(!(str_detect(mother,as.character(counter)) | str_detect(father,as.character(counter))) | (str_detect(mother, substr(proband,1,1)) &amp; str_detect(mother, substr(proband,3,3))) | (str_detect(father, substr(proband,1,1)) &amp; str_detect(father, substr(proband,3,3))) ) geno_novo_all Discard de novo mutations back to the reference allele (e.g. 1/1, 1/1 –&gt; 0/1) since they are unlikely to be pathogenic. geno_novo_not_ref &lt;- wh_geno_auto %&gt;% dplyr::filter(! ( ( ( str_detect(mother, substr(proband,1,1)) | str_detect(mother, &quot;\\\\.&quot;) | substr(proband,1,1)==0 ) &amp; (str_detect(father, substr(proband,3,3)) | str_detect(father, &quot;\\\\.&quot;) | substr(proband,3,3)==0 ) ) | ( ( str_detect(father, substr(proband,1,1)) | str_detect(father, &quot;\\\\.&quot;) | substr(proband,1,1)==0 ) &amp; (str_detect(mother, substr(proband,3,3)) | str_detect(mother, &quot;\\\\.&quot;) | substr(proband,3,3)==0 ) ) ) ) %&gt;% dplyr::filter(!(str_detect(mother,as.character(counter)) | str_detect(father,as.character(counter))) | (str_detect(mother, substr(proband,1,1)) &amp; str_detect(mother, substr(proband,3,3))) | (str_detect(father, substr(proband,1,1)) &amp; str_detect(father, substr(proband,3,3))) ) geno_novo_not_ref[c(1:5)] Increase the cutoff for genotype quality to ensure that the the de novo variants are not a result of incorrect variant calling. Set GQ&gt;=30, i.e, the probability that the call is incorrect is =&lt;0.1%. geno_novo_not_ref_high_qual &lt;- geno_novo_not_ref %&gt;% dplyr::filter(GQ_mother&gt;=30) %&gt;% dplyr::filter(GQ_father&gt;=30) %&gt;% dplyr::filter(GQ_proband&gt;=30) geno_novo_not_ref_high_qual Select de novo variants found in the filtered VEP annotation. For each variant, select a single gene transcript that contains the variant. prob_novo &lt;- refseq %&gt;% inner_join(geno_novo_not_ref) prob_novo &lt;- prob_novo %&gt;% group_by(Uploaded_variation) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) prob_novo_high_qual &lt;- refseq %&gt;% inner_join(geno_novo_not_ref_high_qual) prob_novo_high_qual &lt;- prob_novo_high_qual %&gt;% group_by(Uploaded_variation) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) prob_novo_high_qual 5.3 Homozygous Variants Select the homozygous variants in the proband. geno_hom &lt;- wh_geno_auto %&gt;% dplyr::filter(substr(proband,1,1)==substr(proband,3,3) &amp; substr(proband,1,1) != 0 &amp; substr(proband,1,1) != &quot;.&quot;) geno_hom[c(1:5)] Discard the homozygous variants for which one of the parents is also homozygous (e.g. 1/1, 0/1 -&gt; 1/1) since these variants are unlikely to be pathogenic. geno_hom2 &lt;- geno_hom %&gt;% dplyr::filter(! ( (substr(mother,1,1)==substr(mother,3,3) &amp; substr(mother,1,1)==substr(proband,1,1)) | (substr(father,1,1)==substr(father,3,3) &amp; substr(father,1,1)==substr(proband,1,1)) ) ) geno_hom2[c(1:5)] Select the homozygous variants found in the filtered VEP annotation. For each variant, select a single gene transcript that contains the variant. prob_hom &lt;- refseq %&gt;% inner_join(geno_hom2) prob_hom &lt;- prob_hom %&gt;% group_by(Uploaded_variation) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) prob_hom 5.4 Compound Heterozygous Variants Select the unphased compound heterozygous variants. prob_2plus_het &lt;- refseq %&gt;% dplyr::filter(substr(proband,1,1)!=substr(proband,3,3)) prob_2plus_het &lt;- prob_2plus_het %&gt;% group_by(Feature) %&gt;% dplyr::filter(length(unique(PS_proband))&gt;=2 | length(is.na(PS_proband)[is.na(PS_proband)==TRUE])&gt;=2 ) %&gt;% ungroup() prob_2plus_het2 &lt;- prob_2plus_het %&gt;% group_by(Gene) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) prob_2plus_het2 Select the phased compound heterozygous variants. prob_comp_het &lt;- refseq %&gt;% group_by(Feature, PS_proband) %&gt;% dplyr::filter(any(substr(proband,1,1)&gt;=1 &amp; substr(proband,2,2)==&quot;|&quot;) &amp; any(substr(proband,3,3)&gt;=1 &amp; substr(proband,2,2)==&quot;|&quot;)) prob_comp_het2 &lt;- prob_comp_het %&gt;% group_by(Gene) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) prob_comp_het2 5.5 X Chromosome Remove X chromosome calls that are “heterozygous” for male individuals. wh_geno_X_filt &lt;- wh_geno_X %&gt;% dplyr::filter(( substr(proband,1,1)==substr(proband,3,3) &amp; substr(father,1,1)==substr(father,3,3) )) prob_X &lt;- inner_join(refseq_X, wh_geno_X) %&gt;% group_by(Gene) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) prob_X 5.6 Disease Genes Select one entry for each variant in refseq table, prioritizing canonical and curated transcripts. refseq2 &lt;- refseq01 %&gt;% group_by(Uploaded_variation) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) refseq2 Select variants that fall in green genes from the UK PanelApp renal broad superpanel. # UK Panel App panel &lt;- read_tsv(&quot;renal_superpanel_broad.tsv&quot;) panel_green &lt;- panel %&gt;% dplyr::filter(GEL_Status==3) refseq_green &lt;- refseq2 %&gt;% dplyr::filter(HGNC_ID %in% panel_green$HGNC) #Australia Panel App panel_au &lt;- read_tsv(&quot;Kidneyome_SuperPanel.tsv&quot;) %&gt;% dplyr::filter(!duplicated(HGNC)) %&gt;% dplyr::mutate(Status=case_when( GEL_Status==4|GEL_Status==3 ~ &quot;Green&quot;, GEL_Status==2 ~ &quot;Amber&quot;, GEL_Status==1|GEL_Status==0 ~ &quot;Red&quot;)) %&gt;% dplyr::select(HGNC,Status) refseq_au &lt;- refseq2 %&gt;% inner_join(panel_au, join_by(HGNC_ID==HGNC)) refseq_au Combine annotations. refseq3 &lt;- refseq01 %&gt;% group_by(Gene) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% ungroup() refseq4 &lt;- refseq3 %&gt;% left_join(add_column(geno_novo_not_ref,de_novo=&quot;de_novo&quot;)) %&gt;% left_join(add_column(geno_novo_not_ref_high_qual,de_novo_gq=&quot;de_novo_gq&gt;=30&quot;)) %&gt;% left_join(add_column(geno_hom2, homozygote=&quot;homozygote&quot;)) %&gt;% left_join(add_column(prob_2plus_het, unphased_compound_heterozygote=&quot;unphased_compound_heterozygote&quot;)) %&gt;% left_join(add_column(prob_comp_het, phased_compound_heterozygote=&quot;phased_compound_heterozygote&quot;)) %&gt;% mutate(zygosity=coalesce(de_novo_gq,de_novo,homozygote,phased_compound_heterozygote,unphased_compound_heterozygote)) %&gt;% dplyr::select(-c(de_novo_gq,de_novo,homozygote,phased_compound_heterozygote,unphased_compound_heterozygote)) %&gt;% dplyr::relocate(zygosity,.after=counter) refseq_sum &lt;- refseq4 %&gt;% group_by(Feature) %&gt;% summarize(z=paste(c(Uploaded_variation,Location,Allele,Consequence,Amino_acids,Codons), collapse = &quot; &quot;)) %&gt;% distinct(z,.keep_all = T) refseq5 &lt;- refseq4 %&gt;% dplyr::filter(Feature %in% refseq_sum$Feature) "],["summary.html", "6 Summary", " 6 Summary Output the results of the analysis to an Excel workbook with seperate sheets for de novo, homozygous, unphased compound hetorygous and phased compound heterozygous variants. For compound heterozygous variants, highlight variants in the same transcript with a single colour for ease of viewing. library(openxlsx) names &lt;- c(&quot;de_novo&quot;, &quot;de_novo_gq&gt;=30&quot;,&quot;homozygote&quot;,&quot;unphased_compound_heterozygote&quot;,&quot;phased_compound_heterozygote&quot;,&quot;chrX&quot;,&quot;ukpanelapp_green&quot;,&quot;aupanelapp&quot;,&quot;all_variants&quot;) tables &lt;- c(&quot;prob_novo&quot;,&quot;prob_novo_high_qual&quot;,&quot;prob_hom&quot;,&quot;prob_2plus_het2&quot;,&quot;prob_comp_het2&quot;,&quot;prob_X&quot;,&quot;refseq_green&quot;,&quot;refseq_au&quot;,&quot;refseq5&quot;) sheets &lt;- data_frame(names,tables) wb &lt;- createWorkbook() negStyle &lt;- createStyle(fontColour = &quot;#9C0006&quot;, bgFill = &quot;#FFC7CE&quot;) posStyle &lt;- createStyle(fontColour = &quot;#006100&quot;, bgFill = &quot;#C6EFCE&quot;) for (i in 1:nrow(sheets)) { table &lt;- get(sheets$tables[i]) table$Group &lt;- cumsum(c(TRUE, head(table$Feature, -1) != tail(table$Feature, -1))) e_col &lt;- int2col(ncol(table)) e_col1 &lt;- int2col(ncol(table)+1) e_col2 &lt;- int2col(ncol(table)+2) table$helper1 &lt;- paste(&quot;=SUBTOTAL(103,&quot;,e_col,2:(nrow(table)+1),&quot;)&quot;, sep = &quot;&quot;) table$helper2 &lt;- paste(&quot;=IF(&quot;,e_col1,2:(nrow(table)+1),&quot;=1,IFERROR(MAX($&quot;,e_col2,&quot;$1:&quot;,e_col2,1:nrow(table),&quot;)+(COUNTIFS($&quot;,e_col,&quot;$1:&quot;,e_col,1:nrow(table),&quot;,&quot;,e_col,2:(nrow(table)+1),&quot;,&quot;,&quot;$&quot;,e_col1,&quot;$1:&quot;,e_col1,1:nrow(table),&quot;,1)=0),1),\\&quot;\\&quot;)&quot;, sep = &quot;&quot;) class(table$helper1) &lt;- c(class(table$helper1), &quot;formula&quot;) class(table$helper2) &lt;- c(class(table$helper2), &quot;formula&quot;) addWorksheet(wb, sheets$names[i]) writeDataTable(wb,sheets$names[i], x = table, tableStyle = &quot;None&quot;) rule_odd &lt;- paste(&quot;ISODD($&quot;, e_col2, &quot;1)&quot;, sep = &quot;&quot;, collapse = &quot;&quot;) rule_even &lt;- paste(&quot;ISEVEN($&quot;, e_col2, &quot;1)&quot;, sep = &quot;&quot;, collapse = &quot;&quot;) conditionalFormatting(wb, sheets$names[i], cols = 1:ncol(table), rows = 1:(nrow(table)+1), rule = rule_odd, style = negStyle) conditionalFormatting(wb, sheets$names[i], cols = 1:ncol(table), rows = 1:(nrow(table)+1), rule = rule_even, style = posStyle) } saveWorkbook(wb, &quot;pedigree_results_08_07_23.xlsx&quot;, overwrite = TRUE) "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
