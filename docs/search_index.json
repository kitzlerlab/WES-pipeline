[["index.html", "Whole Exome Sequencing Platform 1 Overview", " Whole Exome Sequencing Platform Marc Henein and Zachary Sentell 2023-09-01 1 Overview This is a pipeline for whole exome sequencing analysis to identify the genetic causes of Mendelian disorders. It was assembled in the Kitzler lab at the McGill University Health Centre and run on the Compute Canada servers. It includes the following steps: Pre-processing of raw reads. Germline variant calling for SNVs and indels. Estimation of kinship coefficients to verify pedigree relationships. Variant annotation and trio analysis to identify disease-causing variants. We follow GATK best practices for pre-processing and variant calling. We execute pre-processing steps with the nf-core/sarek pipeline. We use WhatsHap to phase variants and OpenMendel and PLINK to estimate kinship coefficients. We use Ensembl VEP to annotate variants. We provide R scripts to identify phased compound heterozygous variants as well as de novo, homozygous and unphased compound heterozygous variants. We output the results to Excel in a readable format. We illustrate the expected output and benchmark the pipeline using Illumina paired-end WES data from the GIAB Ashkenazi Jewish reference trio (SRR2962669, SRR2962692, SRR2962694). "],["align.html", "2 Pre-processing 2.1 Sarek Pipeline 2.2 Quality Control of Raw Reads 2.3 Alignment 2.4 Mark Duplicates 2.5 Base Quality Score Recalibration 2.6 Quality Control of Alignment", " 2 Pre-processing 2.1 Sarek Pipeline We execute the raw read pre-processing with the Sarek pipeline using Nextflow. module load nextflow/23.04.3 exome=sureselectV5_padded_hg38.bed nextflow run nf-core-sarek-3.1.2/workflow \\ -profile singularity,beluga --input ./samplesheet_ec.csv --outdir ./results \\ --genome GATK.GRCh38 --intervals $exome \\ --wes --nucleotides_per_second 1000 --save_reference --save_output_as_bam --save_mapped In the following we describe the tools that the command calls with their associated scripts. 2.2 Quality Control of Raw Reads We obtain an overview of the quality of the raw reads with FastQC. module load fastqc/0.11.9 fastqc -t 6 AJ_GIAB_fastq/HG002_1.fastq AJ_GIAB_fastq/HG002_2.fastq FastQC Report for HG002 paired end R1. 2.3 Alignment We trim raw reads with fastp, then map reads to the GRCh38 reference genome with the BWA-MEM algorithm and convert SAM to BAM with samtools. module load fastp/0.23.4 module load bwa module load samtools export reference=$MUGQIC_INSTALL_HOME/genomes/species/Homo_sapiens.GRCh38/ id=&quot;&quot; sm=&quot;HG002&quot; genome/bwa_index/Homo_sapiens.GRCh38.fa fastp -i HG002_1.fq.gz -I HG002_2.fq.gz \\ --stdout --thread 2 \\ -j &quot;fastp-HG002.json&quot; \\ -h &quot;fastp-HG002.html&quot; \\ 2&gt; &quot;fastp-HG002.log&quot; \\ | bwa mem -v 2 -M -t 32 -p \\ -R &quot;@RG\\tID:$id\\tPL:ILLUMINA\\tLB:$id&quot;_&quot;$sm\\tSM:$sm&quot; \\ $reference - 2&gt; &quot;bwa-HG002.log&quot; \\ | samtools view -@ 16 \\ -O BAM \\ -o &quot;aligned_HG002.bam&quot; \\ 2&gt; &quot;samtools-HG002.log&quot; 2.4 Mark Duplicates We identify read pairs that are likely to have originated from duplicates of the same DNA fragment with GATK MarkDuplicates. export GATK_JAR=/cvmfs/soft.mugqic/CentOS6/software/GenomeAnalysisTK/GenomeAnalysisTK-4.1.8.1/gatk-package-4.1.8.1-local.jar java -Xms60G -Xmx60G -jar $GATK_JAR MarkDuplicatesSpark \\ -I aligned_HG002.bam \\ -O aligned_HG002_markdup.bam \\ --spark-master local[12] 2.5 Base Quality Score Recalibration We use BQSR to recalibrate the base quality of reads based on on various covariates, i.e., read group, reported quality score, machine cycle, and nucleotide context. java -Xms4G -Xmx4G -jar $GATK_JAR BaseRecalibrator \\ -I aligned_HG002_markdup.bam \\ -R $reference \\ -O aligned_HG002_markdup_bqsr.report \\ --known-sites BQSR/Homo_sapiens_assembly38.dbsnp138.vcf \\ --known-sites BQSR/Homo_sapiens_assembly38.known_indels.vcf.gz \\ --known-sites BQSR/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz java -Xms2G -Xmx2G -jar $GATK_JAR ApplyBQSR \\ -I aligned_HG002_markdup.bam \\ -R $reference \\ --bqsr-recal-file aligned_HG002_markdup_bqsr.report \\ -O aligned_HG002_markdup_bqsr.bam 2.6 Quality Control of Alignment samtools stats collects statistics from BAM files and outputs in a text format. samtools stats aligned_HG002_markdup_bqsr.bam &gt; aligned_HG002_markdup_bqsr_stats.txt Mosdepth summarizes basic statistics of the alignment (number of reads, coverage, GC-content, etc.) and produces a number of useful graphs. module load mugqic/mosdepth/0.3.4 mosdepth --by $exome HG002_mosdepth_output aligned_HG002_markdup_bqsr.bam MultiQC generates a single HTML report summarizing all samples in the project. module load multiqc multiqc . "],["calling.html", "3 Variant Calling 3.1 SNV/Indel Calling 3.2 Variant Filtration 3.3 Genotype Posteriors 3.4 Benchmarking", " 3 Variant Calling 3.1 SNV/Indel Calling We call variants with GATK4 HaplotypeCaller. exome=sureselectV4_padded_hg38.bed names=&#39;father mother proband&#39; for name in $names do input=&quot;BAM/${name}.recal.bam&quot; output=&quot;${name}_raw_variants.g.vcf.gz&quot; java -Xmx6g -jar $GATK_JAR HaplotypeCaller \\ -R $reference \\ -I $input \\ -O $output \\ -L $exome \\ -ip 0 \\ -ERC GVCF done Then, combine gVCFs and compile genotypes at sites with a variant in at least one sample. # Combine gVCFs find . -maxdepth 1 -type f -name &quot;*_raw_variants.g.vcf.gz&quot; &gt; input.list java -Xmx6g -jar $GATK_JAR CombineGVCFs \\ -R $reference \\ -V input.list \\ -O joint/joint_raw_variants.g.vcf.gz # Genotype gVCF java -Xmx6g -jar $GATK_JAR GenotypeGVCFs \\ -R $reference \\ -V joint/joint_raw_variants.g.vcf.gz \\ -O joint/joint_raw_variants_genotype.vcf.gz 3.2 Variant Filtration For SNVs, we use VQSR to filter variants. VQSR creates a training set of high-confidence variants and learns which region of the parameter space is associated with high quality calls. # Sties only java -Xmx2g -jar $GATK_JAR MakeSitesOnlyVcf \\ -I joint/joint_raw_variants_genotype.vcf.gz \\ -O joint/joint_raw_variants_genotype_sitesonly.vcf.gz # VQSR for SNPs java -Xmx6g -jar $GATK_JAR VariantRecalibrator \\ -R $reference \\ -V joint/joint_raw_variants_genotype_sitesonly.vcf.gz \\ --trust-all-polymorphic \\ -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.8 -tranche 99.6 -tranche 99.5 -tranche 99.4 -tranche 99.3 -tranche 99.0 -tranche 98.0 -tranche 97.0 -tranche 90.0 \\ -an QD -an MQRankSum -an ReadPosRankSum -an FS -an MQ -an SOR -an DP \\ -resource:hapmap,known=false,training=true,truth=true,prior=15 VQSR/hg38/hapmap_3.3.hg38.vcf.gz \\ -resource:omni,known=false,training=true,truth=true,prior=12 VQSR/hg38/1000G_omni2.5.hg38.vcf.gz \\ -resource:1000G,known=false,training=true,truth=false,prior=10 VQSR/hg38/1000G_phase1.snps.high_confidence.hg38.vcf.gz \\ -resource:dbsnp,known=true,training=false,truth=false,prior=7 VQSR/hg38/Homo_sapiens_assembly38.dbsnp138.vcf \\ --max-gaussians 4 \\ -mode SNP \\ -O joint/cohort_snps.recal \\ --tranches-file joint/cohort_snps.tranches \\ --rscript-file joint/output_snp.plots.R java -Xmx6g -jar $GATK_JAR ApplyVQSR \\ -R $reference \\ -V joint/joint_raw_variants_genotype.vcf.gz \\ -O joint/snp.recalibrated.vcf.gz \\ --recal-file joint/cohort_snps.recal \\ --tranches-file joint/cohort_snps.tranches \\ --truth-sensitivity-filter-level 99.7 \\ --create-output-variant-index true \\ -mode SNP We manually filter indels by setting hard thresholds due to the small number of samples. For large numbers of samples, we can use VQSR to filter indels. # Select indels java -Xmx2g -jar $GATK_JAR SelectVariants \\ -R $reference \\ -V joint/joint_raw_variants_genotype.vcf.gz \\ --select-type-to-include INDEL \\ -O joint/raw_indels.vcf.gz # Indels hard threshold java -Xmx2g -jar $GATK_JAR VariantFiltration \\ -R $reference \\ -V joint/raw_indels.vcf.gz \\ -O joint/filtered_indels.vcf.gz \\ -filter &quot;QD &lt; 2.0&quot; --filter-name &quot;QD2&quot; \\ -filter &quot;QUAL &lt; 30.0&quot; --filter-name &quot;QUAL30&quot; \\ -filter &quot;FS &gt; 200.0&quot; --filter-name &quot;FS200&quot; \\ -filter &quot;ReadPosRankSum &lt; -20.0&quot; --filter-name &quot;ReadPosRankSum-20&quot; We merge SNPs and indels into a single VCF. java -Xmx2g -jar $GATK_JAR SelectVariants \\ -R $reference \\ -V joint/snp.recalibrated.vcf.gz \\ --select-type-to-include SNP \\ -O joint/snp.recalibrated_minus_indel.vcf.gz java -Xmx2g -jar $GATK_JAR MergeVcfs \\ -I joint/snp.recalibrated_minus_indel.vcf.gz \\ -I joint/filtered_indels.vcf.gz \\ -O joint/output_vqsr_snps_hard_indels.vcf.gz 3.3 Genotype Posteriors We recalculate the likelihood of the genotypes given pedigree relationships and population allele frequencies. java -Xmx2g -jar $GATK_JAR CalculateGenotypePosteriors \\ -V joint/output_vqsr_snps_hard_indels.vcf.gz \\ -ped pedigree.ped \\ --supporting-callsets af-only-gnomad.hg38.vcf.gz \\ -O trio_refined.vcf.gzb 3.4 Benchmarking We benchmarked the pipeline against the GIAB high-confidence variants calls using the Illumina hap.py VCF comparison tool. We obtain the following results for the proband HG002: Type Truth TP Truth FN Query FP Recall Precision SNP 37653 753 369 98.0% 99.0% INDEL 2732 176 382 93.9% 87.9% "],["statistical-genetics.html", "4 Statistical Genetics 4.1 Phasing 4.2 Kinship 4.3 Runs of Homozygosity 4.4 Linkage Analysis 4.5 Population Substructure", " 4 Statistical Genetics 4.1 Phasing We use WhatsHap to phase genotypes in a pedigree using the Mendelian transmission rules and physical phasing based on reads that span two or more heterozygous variants. whatshap phase --ped pedigree.ped \\ -o phased_whatshap.vcf joint/output_vqsr_variants.vcf.gz \\ aligned_HG002.bam aligned_HG003.bam aligned_HG004.bam \\ --tag=PS --no-reference --indels 4.2 Kinship We seek to verify pedigree relationships and identify hidden relatedness between samples. We first select SNPs in approximate linkage equilibrium with Linkdatagen based on the genetic linkage map of HapMap SNPs. Linkdatagen also eliminates Mendelian inconsitencies in the data. perl vcf2linkdatagen.pl \\ -variantCaller mpileup \\ -annotfile annotHapMap2U.txt \\ -pop CEU -mindepth 10 -missingness 0 \\ -idlist MyVCFlist.txt &gt; MySNPs.brlmm perl linkdatagen.pl \\ -data m -pedfile MyPed.ped \\ -whichSamplesFile MyWS.ws \\ -callFile MySNPs.brlmm \\ -annotFile annotHapMap2U.txt \\ -pop CEU -binsize 0.3 \\ -MendelErrors removeSNPs -prog pl \\ -outputDir MyPed_HapMap2_pl &gt; MyPed_HapMap2_pl.out We construct an allele frequency report for the chosen SNPs. map &lt;- read_delim(file = &quot;plink.map&quot;, delim = &quot; &quot;, col_select = 1:4, col_names = c(&quot;CHR&quot;, &quot;SNP&quot;, &quot;cM&quot;, &quot;bp&quot;)) ord &lt;- read_tsv(file = &quot;orderedSNPs.txt&quot;) freq_pl &lt;- map %&gt;% left_join(ord, by = &quot;SNP&quot;) %&gt;% dplyr::select(CHR, SNP, `Allele freq`) %&gt;% mutate(A1=&quot;1&quot;) %&gt;% mutate(A1=&quot;1&quot;) %&gt;% mutate(A2=&quot;2&quot;) %&gt;% mutate(NCHROBS=&quot;300&quot;) %&gt;% dplyr::select(CHR, SNP, A1, A2, `Allele freq`, NCHROBS) %&gt;% rename(`Allele freq` = &quot;MAF&quot;) write_delim(freq_pl, &quot;freq_pl.frq&quot;, delim = &quot; &quot;) Alternatively, with a sufficient number of samples, we can estimate the linkage disequilibrium between alleles and remove correlated SNPs using PLINK. plink --file data --indep 50 5 2 We then calculate the empirical kinship coefficient by estimating identity by descent using identity by state and allele frequencies (Lange 2002). We run this calculation in PLINK. plink --file plink --genome --read-freq freq_pl.frq We also run this calculation using MendelKinship from the OpenMendel project. using MendelKinship, CSV Kinship(&quot;control_compare.txt&quot;) 4.3 Runs of Homozygosity If we suspect some degree of consanguinity, we may look for a homozygous pathogenic variant in runs of homozygosity using AutozygosityMapper. 4.4 Linkage Analysis Using the same set of SNPs in linkage equillibrium, we can run linkage analysis on appropriately chosen pedigrees using OpenMendel for two-point linkage or multipoint linkage analysis. # Two-point linkage analysis using MendelTwoPointLinkage, CSV TwoPointLinkage(&quot;Control_file.txt&quot;) # Multipoint linkage analysis using MendelLocationScores, CSV LocationScores(&quot;Control_file.txt&quot;) 4.5 Population Substructure Given a large number of samples from a population, we cluster individuals by degree of identity by state using PLINK in order to identify subgroups with shared ancestry. plink --file mydata --cluster # dimensional reduction to 4D then plot two coordinates plink --file mydata --read-genome plink.genome --cluster --mds-plot 4 "],["variant-annotation.html", "5 Variant Annotation 5.1 Filtration 5.2 De Novo Variants 5.3 Homozygous Variants 5.4 Compound Heterozygous Variants 5.5 X Chromosome 5.6 Disease Genes", " 5 Variant Annotation We annotate the variants with VEP for molecular consequence, allele frequency, clinical variant databases, i.e. Clinvar, Mastermind, and a set of pathogenicity prediction tools, i.e., CADD, PrimateAI, SpliceAI, EVE, MutationTaster, REVEL. apptainer exec -B vep_data:/opt/vep/.vep vep.sif /opt/vep/src/ensembl-vep/vep \\ --dir_cache /opt/vep/.vep/ \\ --dir_plugins /opt/vep/.vep/Plugins/ \\ -i /opt/vep/.vep/output_vqsr_snps_hard_indels.vcf.gz \\ -o /opt/vep/.vep/ensembl_annotated.txt \\ --individual EC27_proband \\ --everything \\ --check_existing \\ --xref_refseq \\ --fasta /opt/vep/.vep/Homo_sapiens.GRCh38.fa \\ --hgvs \\ --hgvsg \\ --plugin CADD,/opt/vep/.vep/Plugins/data/grch38/whole_genome_SNVs_grch38.tsv.gz,/opt/vep/.vep/Plugins/data/grch38/gnomad.genomes.r3.0.indel_grch38.tsv.gz \\ --plugin PrimateAI,/opt/vep/.vep/Plugins/data/grch38/PrimateAI_scores_v0.2_GRCh38_sorted.tsv.bgz \\ --plugin SpliceAI,snv=/opt/vep/.vep/Plugins/data/grch38/spliceai_scores.raw.snv.hg38.vcf.gz,indel=/opt/vep/.vep/Plugins/data/grch38/spliceai_scores.raw.indel.hg38.vcf.gz \\ --plugin EVE,file=/opt/vep/.vep/Plugins/data/grch38/eve_merged.vcf.gz \\ --plugin Mastermind,/opt/vep/.vep/Plugins/data/grch38/mastermind_cited_variants_reference-2023.04.02-grch38.vcf.gz \\ --plugin dbNSFP,/opt/vep/.vep/Plugins/data/grch38/dbNSFP4.3a_grch38.gz,MutationTaster_score,MutationTaster_pred \\ --plugin REVEL,/opt/vep/.vep/Plugins/data/grch38/new_tabbed_revel_grch38.tsv.gz \\ --custom /opt/vep/.vep/Plugins/data/grch38/clinvar.vcf.gz,ClinVar,vcf,exact,0,CLNSIG,CLNREVSTAT,CLNDN \\ --cache \\ --merged \\ --offline \\ --use_given_ref \\ --force_overwrite \\ --assembly GRCh38 \\ --fork 2 \\ --buffer_size 1000 \\ --tab 5.1 Filtration We perform a first round of filtering with VEP to reduce the size of the VCF to be loaded into R. In particular, we select variants with high or moderate impact and a gnomAD exome allele frequency smaller than 0.05. apptainer exec -B vep_data:/opt/vep/.vep vep.sif /opt/vep/src/ensembl-vep/filter_vep \\ -i /opt/vep/.vep/ensembl_annotated.txt \\ -out /opt/vep/.vep/ensembl_ann_vep_filt.txt \\ --filter &quot;(IMPACT is HIGH or IMPACT is MODERATE) and (gnomADe_AF &lt;= 0.05 or not gnomADe_AF)&quot; \\ --force_overwrite \\ --format tab We load the phased variants into R and select autosomal variants that have passed all variant calling filters. library(tidyverse) library(VariantAnnotation) # Set sample names mother = &quot;HG004&quot; father = &quot;HG003&quot; proband = &quot;HG002&quot; # Load WhatsHap phased variants wh &lt;- readVcf(&quot;data/AJ_phased_whatshap_refined.vcf&quot;, &quot;hg38&quot;) wh &lt;- expand(wh) # Variant info pos &lt;- rowRanges(wh) %&gt;% as.data.frame() %&gt;% as_tibble() # Genotype wh_geno &lt;- geno(wh)$GT %&gt;% as_tibble() %&gt;% dplyr::rename(&quot;mother&quot;= sym(mother), &quot;father&quot;= sym(father), &quot;proband&quot;= sym(proband)) # Phasing block wh_ps &lt;- geno(wh)$PS %&gt;% as_tibble() %&gt;% dplyr::rename(&quot;PS_mother&quot; = sym(mother), &quot;PS_father&quot;= sym(father), &quot;PS_proband&quot;= sym(proband)) # Genotype quality wh_gq &lt;- geno(wh)$GQ %&gt;% as_tibble() %&gt;% dplyr::rename(&quot;GQ_mother&quot; = sym(mother), &quot;GQ_father&quot;= sym(father), &quot;GQ_proband&quot;= sym(proband)) # Allelic depth wh_ad &lt;- geno(wh)$AD %&gt;% as_tibble() %&gt;% dplyr::rename(&quot;AD_ref_mother&quot; = paste0(sym(mother),&quot;.1&quot;), &quot;AD_ref_father&quot;= paste0(sym(father),&quot;.1&quot;), &quot;AD_ref_proband&quot;= paste0(sym(proband),&quot;.1&quot;)) %&gt;% dplyr::rename(&quot;AD_alt_mother&quot; = paste0(sym(mother),&quot;.2&quot;), &quot;AD_alt_father&quot;= paste0(sym(father),&quot;.2&quot;), &quot;AD_alt_proband&quot;= paste0(sym(proband),&quot;.2&quot;)) # Join variant info, genotype, phasing block, genotype quality and allelic depth wh_geno0 &lt;- bind_cols(pos,wh_geno,wh_gq,wh_ps,wh_ad) # Identify alternate alleles with number wh_geno01 &lt;- wh_geno0 %&gt;% group_by(seqnames,start,end,width,REF) %&gt;% mutate(counter = row_number()) %&gt;% ungroup() %&gt;% dplyr::filter(FILTER==&quot;PASS&quot;) # Convert variant formatting to VEP format. Add 1 to indel start site. wh_geno01 &lt;- wh_geno01 %&gt;% mutate(Location = ifelse( width==1, ifelse( nchar(ALT)==1, paste(seqnames,start,sep=&quot;:&quot;), paste0(seqnames,&quot;:&quot;,start,&quot;-&quot;,start+1)), ifelse( start+1==end, paste0(seqnames,&quot;:&quot;,start+1), paste0(seqnames,&quot;:&quot;,start+1,&quot;-&quot;,end)))) %&gt;% mutate(Allele = ifelse(substr(REF,1,1)==substr(ALT,1,1), substr(ALT,2,nchar(ALT)), ALT)) wh_geno01$Allele[wh_geno01$Allele==&quot;&quot;] &lt;- &quot;-&quot; # Overlapping deletions wh_geno_overlap &lt;- wh_geno01 %&gt;% dplyr::filter(ALT==&quot;&quot;) wh_geno1 &lt;- wh_geno01 %&gt;% dplyr::filter(ALT!=&quot;&quot;) # Select columns wh_geno1 &lt;- wh_geno1[c(27,28,11:25,26)] # Select X chromosome wh_geno_X &lt;- wh_geno1 %&gt;% dplyr::filter(str_detect(Location,&quot;chrX&quot;)) # Select autosomal variants wh_geno_auto &lt;- wh_geno1 %&gt;% dplyr::filter(!str_detect(Location,&quot;chrX&quot;)) %&gt;% dplyr::filter(!str_detect(Location,&quot;chrY&quot;)) %&gt;% dplyr::filter(!str_detect(Location,&quot;M&quot;)) Manually remove the hashtag before the line of column titles in ensembl_ann_vep_filt.txt. We load the VEP annotated variants into R and select variants with an allele frequency &lt;0.01 that fall in RefSeq transcripts. result &lt;- read_table(&quot;data/AJ_ensembl_ann_vep_filt_09_01_23.txt&quot;, comment = &quot;#&quot;, na=&quot;-&quot;, col_types = list( Uploaded_variation= col_factor(), Gene=col_factor(), Feature=col_factor(), MANE_PLUS_CLINICAL = col_character(), MOTIF_NAME = col_character(), HIGH_INF_POS = col_character(), TRANSCRIPTION_FACTORS = col_character(), PUBMED=col_character(), MOTIF_POS = col_character())) result$Allele[is.na(result$Allele)] &lt;- &quot;-&quot; result1 &lt;- result %&gt;% as_tibble %&gt;% left_join(wh_geno1, by = c(&quot;Location&quot;,&quot;Allele&quot;)) refseq0 &lt;- result1 %&gt;% dplyr::filter(SOURCE == &quot;RefSeq&quot;) %&gt;% dplyr::filter(gnomADe_AF&lt;=0.01|is.na(gnomADe_AF)) %&gt;% dplyr::filter(!(is.na(gnomADe_AF) &amp; gnomADg_AF &gt; 0.01)) %&gt;% dplyr::filter(!(str_detect(Feature,&quot;XM&quot;))) %&gt;% select_if(~any(!is.na(.))) We add gene-level information from OMIM, Human Phenotype Ontology, ClinGen, GenCC, Orphanet. library(ontologyIndex) # OMIM omim &lt;- read_tsv(&quot;data/genemap2_edit.txt&quot;, name_repair=&quot;universal&quot;, col_types=list(Entrez.Gene.ID = col_factor())) %&gt;% dplyr::rename(OMIM_Phenotypes = Phenotypes) %&gt;% dplyr::select(Entrez.Gene.ID,OMIM_Phenotypes) # Human Phenotype Ontology hpo_data &lt;- read_tsv(&quot;data/genes_to_phenotype.txt&quot;, col_types=list(entrez_gene_id = col_factor())) hpo &lt;- get_ontology(file = &#39;data/hp_obo.txt&#39;, propagate_relationships = &quot;is_a&quot;, extract_tags = &quot;minimal&quot;) hpo_kidney &lt;- get_descendants(hpo, roots=&quot;HP:0000077&quot;) #Abnormality of the kidney gen_hpo_kidney &lt;- hpo_data %&gt;% dplyr::filter(hpo_term_id %in% hpo_kidney) %&gt;% dplyr::arrange(frequency_hpo) %&gt;% dplyr::mutate(frequency = case_when( frequency_hpo == &quot;HP:0040284&quot; ~ &quot; (very rare)&quot;, frequency_hpo == &quot;HP:0040283&quot; ~ &quot; (occasional)&quot;, frequency_hpo == &quot;HP:0040282&quot; ~ &quot; (frequent)&quot;, frequency_hpo == &quot;HP:0040281&quot; ~ &quot; (very frequent)&quot;, frequency_hpo == &quot;HP:0040280&quot; ~ &quot; (obligate)&quot;, TRUE ~ &quot;&quot;)) %&gt;% unite(&quot;renal_hpo_term&quot;, c(hpo_term_name, frequency), remove = FALSE, sep = &quot;&quot;) %&gt;% dplyr::group_by(entrez_gene_id) %&gt;% dplyr::summarise(renal_hpo_term = toString(unique(renal_hpo_term))) gen_hpo_extra &lt;- hpo_data %&gt;% dplyr::filter(frequency_hpo %in% c(&quot;HP:0040281&quot;, &quot;HP:0040280&quot;)) %&gt;% dplyr::arrange(frequency_hpo) %&gt;% dplyr::filter(!(hpo_term_id %in% hpo_kidney)) %&gt;% dplyr::group_by(entrez_gene_id) %&gt;% dplyr::summarise(extrarenal_hpo_term = toString(unique(hpo_term_name))) # ClinGen clingen &lt;- read_csv(&quot;data/Clingen-Curation.csv&quot;, skip = 3) %&gt;% dplyr::mutate(assertion=gsub(&quot;\\\\s*\\\\([^\\\\)]+\\\\)&quot;,&quot;&quot;, gene_disease_validity_assertion_classifications)) %&gt;% dplyr::mutate(assertion=paste(&quot;(&quot;,assertion,&quot;)&quot;,sep=&quot;&quot;)) %&gt;% dplyr::mutate(assertion=if_else(assertion==&quot;(NA)&quot;,NA,assertion)) %&gt;% unite(&quot;disease&quot;, c(disease_label, assertion), remove = FALSE, na.rm=TRUE, sep = &quot; &quot;) %&gt;% dplyr::group_by(hgnc_id) %&gt;% dplyr::summarise(clingen_disease_label = paste(disease,collapse=&quot;; &quot;)) # GenCC including Orphanet data gencc &lt;- read_tsv(&quot;data/gencc-submissions.tsv&quot;) gencc_def &lt;- gencc %&gt;% dplyr::filter(submitter_title != &quot;Orphanet&quot;) %&gt;% dplyr::filter(classification_title == &quot;Definitive&quot;) %&gt;% dplyr::group_by(gene_symbol, gene_curie, disease_title) %&gt;% dplyr::summarise( submitter_title = toString(unique(submitter_title)), moi_title = toString(unique(moi_title)), disease_curie = toString(unique(disease_curie)), disease_original_curie = toString(unique(disease_original_curie)), classification_title = toString(classification_title), submitted_as_pmids = toString(unique(submitted_as_pmids))) %&gt;% dplyr::mutate(submitter = paste(&quot;(&quot;, submitter_title, &quot;)&quot;, sep = &quot;&quot;)) %&gt;% tidyr::unite(&quot;gencc_disease_definitive&quot;, c(disease_title, submitter), remove = FALSE, sep = &quot; &quot;) %&gt;% dplyr::select(gene_curie, gencc_disease_definitive) %&gt;% dplyr::group_by(gene_curie) %&gt;% dplyr::summarise(gencc_disease_definitive = paste(unique(gencc_disease_definitive), collapse=&quot;; &quot;)) gencc_strong &lt;- gencc %&gt;% dplyr::filter(submitter_title != &quot;Orphanet&quot;) %&gt;% dplyr::filter(classification_title == &quot;Strong&quot;) %&gt;% dplyr::group_by(gene_symbol, gene_curie, disease_title) %&gt;% dplyr::summarise( submitter_title = toString(unique(submitter_title)), moi_title = toString(unique(moi_title)), disease_curie = toString(unique(disease_curie)), disease_original_curie = toString(unique(disease_original_curie)), classification_title = toString(classification_title), submitted_as_pmids = toString(unique(submitted_as_pmids))) %&gt;% dplyr::mutate(submitter = paste(&quot;(&quot;, submitter_title, &quot;)&quot;, sep = &quot;&quot;)) %&gt;% tidyr::unite(&quot;gencc_disease_strong&quot;, c(disease_title, submitter), remove = FALSE, sep = &quot; &quot;) %&gt;% dplyr::select(gene_curie, gencc_disease_strong) %&gt;% dplyr::group_by(gene_curie) %&gt;% dplyr::summarise(gencc_disease_strong = paste(unique(gencc_disease_strong), collapse=&quot;; &quot;)) orphanet &lt;- gencc %&gt;% dplyr::filter(submitter_title == &quot;Orphanet&quot;) %&gt;% dplyr::group_by(gene_curie) %&gt;% dplyr::summarise(orphanet_disease = toString(disease_title), orphanet_moi = toString(unique(moi_title))) # Join refseq01 &lt;- refseq0 %&gt;% left_join(omim, by=join_by(Gene==Entrez.Gene.ID)) %&gt;% left_join(gen_hpo_kidney, by=join_by(Gene==entrez_gene_id)) %&gt;% left_join(gen_hpo_extra, by=join_by(Gene==entrez_gene_id)) %&gt;% left_join(clingen, by=join_by(HGNC_ID==hgnc_id)) %&gt;% left_join(gencc_def, by=join_by(HGNC_ID==gene_curie)) %&gt;% left_join(gencc_strong, by=join_by(HGNC_ID==gene_curie)) %&gt;% left_join(orphanet, by=join_by(HGNC_ID==gene_curie)) %&gt;% dplyr::select(SYMBOL, Uploaded_variation, Location, Feature, HGVSc, HGVSp, Consequence, ZYG, EXON, INTRON, gnomADe_AF, gnomADg_AF, MAX_AF, MAX_AF_POPS, ClinVar, ClinVar_CLNSIG, OMIM_Phenotypes, renal_hpo_term, extrarenal_hpo_term, REVEL, SIFT, PolyPhen, CADD_PHRED, PrimateAI, SpliceAI_pred, EVE_CLASS, EVE_SCORE, MutationTaster_pred, MutationTaster_score, orphanet_disease, orphanet_moi, Mastermind_MMID3, Existing_variation, PUBMED, mother, father, proband, Allele, counter, AD_ref_mother, AD_ref_father, AD_ref_proband, AD_alt_mother, AD_alt_father, AD_alt_proband, GQ_mother, GQ_father, GQ_proband, PS_mother, PS_father, PS_proband, CANONICAL, MANE_SELECT, MANE_PLUS_CLINICAL, IMPACT, Gene, HGNC_ID, Amino_acids, Codons, AF, AFR_AF, AMR_AF, EAS_AF, EUR_AF, SAS_AF, gnomADe_AFR_AF, gnomADe_AMR_AF, gnomADe_ASJ_AF, gnomADe_EAS_AF, gnomADe_FIN_AF, gnomADe_NFE_AF, gnomADe_OTH_AF, gnomADe_SAS_AF, gnomADg_AFR_AF, gnomADg_AMI_AF, gnomADg_AMR_AF, gnomADg_ASJ_AF, gnomADg_EAS_AF, gnomADg_FIN_AF, gnomADg_MID_AF, gnomADg_NFE_AF, gnomADg_OTH_AF, gnomADg_SAS_AF) # X chromosome refseq_X &lt;- refseq01 %&gt;% dplyr::filter(str_detect(Uploaded_variation,&quot;X&quot;)) # Autosomal chromosomes refseq &lt;- refseq01 %&gt;% dplyr::filter(!str_detect(Uploaded_variation,&quot;X&quot;)) %&gt;% dplyr::filter(!str_detect(Uploaded_variation,&quot;Y&quot;)) %&gt;% dplyr::filter(!str_detect(Uploaded_variation,&quot;M&quot;)) 5.2 De Novo Variants We select de novo variants in the proband. geno_novo_all &lt;- wh_geno_auto %&gt;% dplyr::filter(! ( ( ( str_detect(mother, substr(proband,1,1)) | str_detect(mother, &quot;\\\\.&quot;) ) &amp; (str_detect(father, substr(proband,3,3)) | str_detect(father, &quot;\\\\.&quot;) ) ) | ( ( str_detect(father, substr(proband,1,1)) | str_detect(father, &quot;\\\\.&quot;) ) &amp; (str_detect(mother, substr(proband,3,3)) | str_detect(mother, &quot;\\\\.&quot;) ) ) ) ) %&gt;% dplyr::filter(!(str_detect(mother,as.character(counter)) | str_detect(father,as.character(counter))) | (str_detect(mother, substr(proband,1,1)) &amp; str_detect(mother, substr(proband,3,3))) | (str_detect(father, substr(proband,1,1)) &amp; str_detect(father, substr(proband,3,3))) ) We discard de novo mutations back to the reference allele (e.g. 1/1, 1/1 –&gt; 0/1) since they are unlikely to be pathogenic. geno_novo_not_ref &lt;- wh_geno_auto %&gt;% dplyr::filter(! ( ( ( str_detect(mother, substr(proband,1,1)) | str_detect(mother, &quot;\\\\.&quot;) | substr(proband,1,1)==0 ) &amp; (str_detect(father, substr(proband,3,3)) | str_detect(father, &quot;\\\\.&quot;) | substr(proband,3,3)==0 ) ) | ( ( str_detect(father, substr(proband,1,1)) | str_detect(father, &quot;\\\\.&quot;) | substr(proband,1,1)==0 ) &amp; (str_detect(mother, substr(proband,3,3)) | str_detect(mother, &quot;\\\\.&quot;) | substr(proband,3,3)==0 ) ) ) ) %&gt;% dplyr::filter(!(str_detect(mother,as.character(counter)) | str_detect(father,as.character(counter))) | (str_detect(mother, substr(proband,1,1)) &amp; str_detect(mother, substr(proband,3,3))) | (str_detect(father, substr(proband,1,1)) &amp; str_detect(father, substr(proband,3,3))) ) We increase the cutoff for genotype quality to ensure that the the de novo variants are not a result of incorrect variant calling. Set GQ&gt;=30, i.e, the probability that the call is incorrect is =&lt;0.1%. geno_novo_not_ref_high_qual &lt;- geno_novo_not_ref %&gt;% dplyr::filter(GQ_mother&gt;=30) %&gt;% dplyr::filter(GQ_father&gt;=30) %&gt;% dplyr::filter(GQ_proband&gt;=30) We select de novo variants found in the filtered VEP annotation. For each variant, we chose a single gene transcript that contains the variant, prioritizing canonical and curated transcripts. prob_novo &lt;- refseq %&gt;% inner_join(geno_novo_not_ref) prob_novo &lt;- prob_novo %&gt;% group_by(Uploaded_variation) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) prob_novo_high_qual &lt;- refseq %&gt;% inner_join(geno_novo_not_ref_high_qual) prob_novo_high_qual &lt;- prob_novo_high_qual %&gt;% group_by(Uploaded_variation) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) 5.3 Homozygous Variants We select the homozygous variants in the proband. geno_hom &lt;- wh_geno_auto %&gt;% dplyr::filter(substr(proband,1,1)==substr(proband,3,3) &amp; substr(proband,1,1) != 0 &amp; substr(proband,1,1) != &quot;.&quot;) We discard the homozygous variants for which one of the parents is also homozygous (e.g. 1/1, 0/1 -&gt; 1/1) since these variants are unlikely to be pathogenic. geno_hom2 &lt;- geno_hom %&gt;% dplyr::filter(! ( (substr(mother,1,1)==substr(mother,3,3) &amp; substr(mother,1,1)==substr(proband,1,1)) | (substr(father,1,1)==substr(father,3,3) &amp; substr(father,1,1)==substr(proband,1,1)) ) ) We select the homozygous variants found in the filtered VEP annotation. prob_hom &lt;- refseq %&gt;% inner_join(geno_hom2) prob_hom &lt;- prob_hom %&gt;% group_by(Uploaded_variation) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) 5.4 Compound Heterozygous Variants We select the unphased compound heterozygous variants. prob_2plus_het &lt;- refseq %&gt;% dplyr::filter(substr(proband,1,1)!=substr(proband,3,3)) prob_2plus_het &lt;- prob_2plus_het %&gt;% group_by(Feature) %&gt;% dplyr::filter(length(unique(PS_proband))&gt;=2 | length(is.na(PS_proband)[is.na(PS_proband)==TRUE])&gt;=2 ) %&gt;% ungroup() prob_2plus_het2 &lt;- prob_2plus_het %&gt;% group_by(Gene) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) We select the phased compound heterozygous variants. prob_comp_het &lt;- refseq %&gt;% group_by(Feature, PS_proband) %&gt;% dplyr::filter(any(substr(proband,1,1)&gt;=1 &amp; substr(proband,2,2)==&quot;|&quot;) &amp; any(substr(proband,3,3)&gt;=1 &amp; substr(proband,2,2)==&quot;|&quot;)) prob_comp_het2 &lt;- prob_comp_het %&gt;% group_by(Gene) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) 5.5 X Chromosome We remove X chromosome calls that are “heterozygous” for male individuals, proband and father. wh_geno_X_filt &lt;- wh_geno_X %&gt;% dplyr::filter(( substr(proband,1,1)==substr(proband,3,3) &amp; substr(father,1,1)==substr(father,3,3))) prob_X &lt;- inner_join(refseq_X, wh_geno_X) %&gt;% group_by(Gene) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) 5.6 Disease Genes We select one entry for each variant in the refseq table, prioritizing canonical and curated transcripts. refseq2 &lt;- refseq01 %&gt;% group_by(Uploaded_variation) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% dplyr::filter(Feature == Feature[1]) We select variants that fall in green genes from the UK PanelApp renal broad superpanel. # UK Panel App panel &lt;- read_tsv(&quot;data/renal_superpanel_broad.tsv&quot;) panel_green &lt;- panel %&gt;% dplyr::filter(GEL_Status==3) refseq_green &lt;- refseq2 %&gt;% dplyr::filter(HGNC_ID %in% panel_green$HGNC) #Australia Panel App panel_au &lt;- read_tsv(&quot;data/Kidneyome_SuperPanel.tsv&quot;) %&gt;% dplyr::filter(!duplicated(HGNC)) %&gt;% dplyr::mutate(Status=case_when( GEL_Status==4|GEL_Status==3 ~ &quot;Green&quot;, GEL_Status==2 ~ &quot;Amber&quot;, GEL_Status==1|GEL_Status==0 ~ &quot;Red&quot;)) %&gt;% dplyr::select(HGNC,Status) refseq_au &lt;- refseq2 %&gt;% inner_join(panel_au, join_by(HGNC_ID==HGNC)) We combine annotations into a single table. refseq3 &lt;- refseq01 %&gt;% group_by(Gene) %&gt;% arrange(desc(CANONICAL), as.character(Feature),.by_group = T) %&gt;% ungroup() refseq4 &lt;- refseq3 %&gt;% left_join(add_column(geno_novo_not_ref,de_novo=&quot;de_novo&quot;)) %&gt;% left_join(add_column(geno_novo_not_ref_high_qual,de_novo_gq=&quot;de_novo_gq&gt;=30&quot;)) %&gt;% left_join(add_column(geno_hom2, homozygote=&quot;homozygote&quot;)) %&gt;% left_join(add_column(prob_2plus_het, unphased_compound_heterozygote=&quot;unphased_compound_heterozygote&quot;)) %&gt;% left_join(add_column(prob_comp_het, phased_compound_heterozygote=&quot;phased_compound_heterozygote&quot;)) %&gt;% mutate(zygosity=coalesce(de_novo_gq,de_novo,homozygote,phased_compound_heterozygote,unphased_compound_heterozygote)) %&gt;% dplyr::select(-c(de_novo_gq,de_novo,homozygote,phased_compound_heterozygote,unphased_compound_heterozygote)) %&gt;% dplyr::relocate(zygosity,.after=counter) refseq_sum &lt;- refseq4 %&gt;% group_by(Feature) %&gt;% summarize(z=paste(c(Uploaded_variation,Location,Allele,Consequence,Amino_acids,Codons), collapse = &quot; &quot;)) %&gt;% distinct(z,.keep_all = T) refseq5 &lt;- refseq4 %&gt;% dplyr::filter(Feature %in% refseq_sum$Feature) "],["summary.html", "6 Summary", " 6 Summary We ouput the results of the analysis to an Excel workbook with seperate sheets for de novo, homozygous, unphased compound hetorygous and phased compound heterozygous variants. We highlight variants in the same transcript with a single colour for ease of viewing. library(openxlsx) names &lt;- c(&quot;de_novo&quot;, &quot;de_novo_gq&gt;=30&quot;,&quot;homozygote&quot;,&quot;unphased_compound_heterozygote&quot;,&quot;phased_compound_heterozygote&quot;,&quot;chrX&quot;,&quot;ukpanelapp_green&quot;,&quot;aupanelapp&quot;,&quot;all_variants&quot;) tables &lt;- c(&quot;prob_novo&quot;,&quot;prob_novo_high_qual&quot;,&quot;prob_hom&quot;,&quot;prob_2plus_het2&quot;,&quot;prob_comp_het2&quot;,&quot;prob_X&quot;,&quot;refseq_green&quot;,&quot;refseq_au&quot;,&quot;refseq5&quot;) sheets &lt;- data_frame(names,tables) wb &lt;- createWorkbook() negStyle &lt;- createStyle(fontColour = &quot;#215967&quot;, bgFill = &quot;#B7DEE8&quot;) posStyle &lt;- createStyle(fontColour = &quot;#006100&quot;, bgFill = &quot;#C6EFCE&quot;) for (i in 1:nrow(sheets)) { table &lt;- get(sheets$tables[i]) table$Group &lt;- cumsum(c(TRUE, head(table$Feature, -1) != tail(table$Feature, -1))) e_col &lt;- int2col(ncol(table)) e_col1 &lt;- int2col(ncol(table)+1) e_col2 &lt;- int2col(ncol(table)+2) table$helper1 &lt;- paste(&quot;=SUBTOTAL(103,&quot;,e_col,2:(nrow(table)+1),&quot;)&quot;, sep = &quot;&quot;) table$helper2 &lt;- paste(&quot;=IF(&quot;,e_col1,2:(nrow(table)+1),&quot;=1,IFERROR(MAX($&quot;,e_col2,&quot;$1:&quot;,e_col2,1:nrow(table),&quot;)+(COUNTIFS($&quot;,e_col,&quot;$1:&quot;,e_col,1:nrow(table),&quot;,&quot;,e_col,2:(nrow(table)+1),&quot;,&quot;,&quot;$&quot;,e_col1,&quot;$1:&quot;,e_col1,1:nrow(table),&quot;,1)=0),1),\\&quot;\\&quot;)&quot;, sep = &quot;&quot;) class(table$helper1) &lt;- c(class(table$helper1), &quot;formula&quot;) class(table$helper2) &lt;- c(class(table$helper2), &quot;formula&quot;) addWorksheet(wb, sheets$names[i]) writeDataTable(wb,sheets$names[i], x = table, tableStyle = &quot;None&quot;) rule_odd &lt;- paste(&quot;ISODD($&quot;, e_col2, &quot;1)&quot;, sep = &quot;&quot;, collapse = &quot;&quot;) rule_even &lt;- paste(&quot;ISEVEN($&quot;, e_col2, &quot;1)&quot;, sep = &quot;&quot;, collapse = &quot;&quot;) conditionalFormatting(wb, sheets$names[i], cols = 1:ncol(table), rows = 1:(nrow(table)+1), rule = rule_odd, style = negStyle) conditionalFormatting(wb, sheets$names[i], cols = 1:ncol(table), rows = 1:(nrow(table)+1), rule = rule_even, style = posStyle) } saveWorkbook(wb, &quot;result/AJ_pedigree_results_09_01_23.xlsx&quot;, overwrite = TRUE) "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
